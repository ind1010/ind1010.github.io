<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Indu Panigrahi</title>
  
  <meta name="author" content="<b>Indu Panigrahi</b>">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
  <link rel="icon" type="image/png" href="images/seal_icon.png">
</head>

<!-- COLOR OPTIONS: 84D66D for green, 942193 for plum, 64D639 for another green, FF9300 for orange -->

<!-- <div class="header">
  <div class="header-right">
    <a href="index.html"><b>Home</b></a>
    <a href="teaching.html"><b>Teaching</b></a>
    <a href="bio.html"><b>Bio</b></a>
    <a href="join.html"><b>Join Us!</b></a>
  </div>
</div> -->

<body>
<aside class="sidebar">
            <!-- <h2>Table of Contents</h2> -->
            <ul>
                <li><a href="#about">About</a></li>
                <li><a href="#publications">Publications</a></li>
                <li><a href="#resexp">More Research</a></li>
                <li><a href="#projects">Course Projects</a></li>
                <li><a href="#teaching">Teaching & Outreach</a></li>
                <li><a href="#committee">Committee Service</a></li>
                <!-- <li><a href="#education">Education</a></li> -->
            </ul>
        </aside>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle" id="about">

              <p style="text-align:center">
                <name>Indu Panigrahi</name>
              </p>
              <p>Hi! I'm a Ph.D. student in the <a href="https://siebelschool.illinois.edu/">Siebel School for Computing and Data Science</a> at the University of Illinois Urbana-Champaign where I am advised by <a href="https://talaugust.github.io/">Prof. Tal August</a>. <br><br>

                My research interests generally lie in human-computer interaction, machine learning, and explainable AI. During my Master's, I primarily focused on explainability in computer vision from a human-centered perspective, and during my undergrad, I worked on developing data-efficient computer vision techniques for analyzing a rock sample dataset. <br><br>

                I previously completed my Master's and Bachelor's in the <a href="https://www.cs.princeton.edu/">Department of Computer Science</a> at Princeton where I worked with <a href="https://parastooabtahi.com/">Prof. Parastoo Abtahi</a>, <a href="https://www.ruthfong.com/">Dr. Ruth Fong</a>, and <a href="https://maloof.princeton.edu/">Prof. Adam Maloof</a>.

                <!--  I previously completed my Master's and Bachelor's <a href="https://www.cs.princeton.edu/">Department of Computer Science</a> at Princeton University where I also completed my B.S.E. in Computer Science in 2023 (along with a minor in statistics and machine learning). I currently work with <a href="https://www.ruthfong.com/">Dr. Ruth Fong</a> and <a href="https://parastooabtahi.com/">Prof. Parastoo Abtahi</a>. <br><br> -->

              <!-- My research interests generally lie in machine learning, explainable AI, and human-computer interaction (within AI/ML). During my Master's, I have primarily focused on explainability in computer vision and robotics from a human-centered perspective. Under the co-advisorship of <a href="https://maloof.princeton.edu/">Prof. Adam Maloof</a> (Department of Geosciences) and Dr. Ruth Fong, I worked on developing data-efficient computer vision techniques for analyzing a rock sample dataset during my undergrad. -->
              <br>
              </p>
              <p style="text-align:center">
                <a href="mailto:indup2@illinois.edu">Email</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?hl=en&user=-ulv8dcAAAAJ">Google Scholar</a> &nbsp/&nbsp
                <!-- <a href="data/indup_cv.pdf">CV</a> &nbsp/&nbsp -->
                <!-- <a href="data/JonBarron-bio.txt">Bio</a> &nbsp/&nbsp -->
                <!-- <a href="https://scholar.google.com/citations?hl=en&user=jktWnL8AAAAJ">Google Scholar</a> &nbsp/&nbsp -->
                <!-- <a href="https://twitter.com/jon_barron">Twitter</a> &nbsp/&nbsp -->
                <a href="https://github.com/ind1010/">GitHub</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/ipanigrahi/">LinkedIn</a> &nbsp/&nbsp
                <a href="https://bsky.app/profile/indupanigrahi.bsky.social">BlueSky</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/indu_profile.jpeg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/indu_profile.jpeg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        
<!-- NEWS -->
     <!--    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
                    <tr>
                    <td style="padding:20px;width:100%;vertical-align:bottom">
                      <heading><i class="fa fa-newspaper-o" aria-hidden="true" style="color:#005CE6"></i> News</heading>
                      <p>
                        <b>> September 2024:</b> Began my 2nd year of my Master's <br>
                        <b>> June 2024:</b> Led the <a href="https://xai4cv.github.io/workshop_cvpr24">Explainable AI for Computer Vision Workshop</a> at CVPR 2024 in Seattle! <br>
                        <b>> July 2024:</b> Attended the AI4ALL and SRC closing programs; amazing work <br>
                        <b>> September 2023:</b> Began my Master's <br>
                      </p>
                    </td>
                  </tr>
                </tbody></table> -->

<!-- PUBLICATIONS -->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:100%;vertical-align:bottom" id="publications">
              <heading><i class="fa fa-book" aria-hidden="true" style="color:#005CE6"></i> Publications & Preprints</heading>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr onmouseout="mip360_stop()" onmouseover="mip360_start()"  bgcolor="#ffffff">
            <td style="padding:20px;width:25%;vertical-align:middle;">
              <!-- <div class="one"> -->
                <!-- <div class="two" id='mip360_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/segmented_flipbook.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div> -->
                <img src='images/interactivity.png' width="100%">
              <!-- </div> -->
              <!-- <script type="text/javascript">
                function mip360_start() {
                  document.getElementById('mip360_image').style.opacity = "1";
                }

                function mip360_stop() {
                  document.getElementById('mip360_image').style.opacity = "0";
                }
                mip360_stop()
              </script> -->
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <!-- <a href="http://jonbarron.info/mipnerf360"> -->
                <papertitle><a href="https://ind1010.github.io/data/interactivity_panigrahi_chiea25.pdf" style="font-size:18px">Interactivity x Explainability: Toward Understanding How Interactivity Can Improve Computer Vision Explanations</a></papertitle>
              <!-- </a> -->
              <br>
              <strong>Indu Panigrahi</strong>, Sunnie S. Y. Kim*, Amna Liaqat*, Rohan Jinturkar, Olga Russakovsky, Ruth Fong, Parastoo Abtahi
              <br>
              <em>CHI Late-Breaking Work</em>, 2025 <br>
              <a href="https://ind1010.github.io/data/interactivity_panigrahi_chiea25.pdf">extended abstract</a>
              /
              <a href="https://ind1010.github.io/interactive_XAI">project page</a>
              /
              <a href="https://youtu.be/9UpFqSNbIdc?feature=shared">talk</a>
              <p>Explored how end-users leverage and perceive interactive computer vision explanations.</p>
            </td>
          </tr> 

          <tr onmouseout="mip360_stop()" onmouseover="mip360_start()"  bgcolor="#ffffff">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <!-- <div class="one"> -->
                <!-- <div class="two" id='mip360_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/editing_moving.mov" type="video/mp4">
                Your browser does not support the video tag.
                </video></div> -->
                <img src='images/editing_still.jpg' width="100%">
              <!-- </div> -->
              <!-- <script type="text/javascript">
                function mip360_start() {
                  document.getElementById('mip360_image').style.opacity = "1";
                }

                function mip360_stop() {
                  document.getElementById('mip360_image').style.opacity = "0";
                }
                mip360_stop()
              </script> -->
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <!-- <a href="http://jonbarron.info/mipnerf360"> -->
                <papertitle><a href="https://openaccess.thecvf.com/content/CVPR2023W/L3D-IVU/html/Panigrahi_Improving_Data-Efficient_Fossil_Segmentation_via_Model_Editing_CVPRW_2023_paper.html" style="font-size:18px">Improving Data-Efficient Fossil Segmentation via Model Editing</a></papertitle>
              <!-- </a> -->
              <br>
              <strong>Indu Panigrahi</strong>, Ryan Manzuk, Ruth Fong, Adam Maloof
              <br>
              <em>CVPR Workshop on Learning with Limited Labelled Data for Image and Video Understanding</em>, 2023 <br>
              Also presented at CVPR 2023 Women in Computer Vision Workshop <br>
              <b style="color:#FF9300"><i class="fa fa-trophy" aria-hidden="true" style="color:#FF9300"></i>
Computer Science Outstanding Independent Work Award</b>
              <br>
              <a href="https://openaccess.thecvf.com/content/CVPR2023W/L3D-IVU/html/Panigrahi_Improving_Data-Efficient_Fossil_Segmentation_via_Model_Editing_CVPRW_2023_paper.html">paper</a>
              /
              <a href="https://drive.google.com/file/d/1J6V_rp5ATMh6_l_bctm09AG8ag5Krhm-/view?usp=sharing">poster</a>
              /
              <a href="https://youtu.be/9kd1pSDxUAU?feature=shared">5 min. talk</a>
              /
              <a href="https://youtu.be/y5zCs_SG5wY?feature=shared">8 min. talk</a>
              <p>Extended a model-editing technique and conducted extensive experiments to investigate and mitigate systematic mistakes made by a model for fossil segmentation. Originally for my Spring 2022 Junior Independent Work.</p>
            </td>
          </tr> 

          <tr onmouseout="mip360_stop()" onmouseover="mip360_start()"  bgcolor="#ffffff">
            <td style="padding:20px;width:25%;vertical-align:middle;">
              <!-- <div class="one"> -->
                <!-- <div class="two" id='mip360_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/segmented_flipbook.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div> -->
                <img src='images/bus.jpg' width="100%">
              <!-- </div> -->
              <!-- <script type="text/javascript">
                function mip360_start() {
                  document.getElementById('mip360_image').style.opacity = "1";
                }

                function mip360_stop() {
                  document.getElementById('mip360_image').style.opacity = "0";
                }
                mip360_stop()
              </script> -->
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <!-- <a href="http://jonbarron.info/mipnerf360"> -->
                <papertitle><a href="https://arxiv.org/abs/2210.03646" style="font-size:18px">Leveraging Structure from Motion to Localize Inaccessible Bus Stops</a></papertitle>
              <!-- </a> -->
              <br>
              <strong>Indu Panigrahi</strong>, Tom Bu, Christoph Mertz
              <br>
              <em>arXiv</em>, 2022 <br>
              Work done while interning at the Robotics Institute as a <a href="https://riss.ri.cmu.edu/meet-the-2022-ri-summer-scholars/">RISS scholar</a>
              <br>
              <a href="https://arxiv.org/abs/2210.03646">preprint</a>
              /
              <a href="https://drive.google.com/file/d/1aU9z8YWIrs2wTA2QxrgYlCjgsdcln8I4/view?usp=sharing">poster</a>
              /
              <a href="https://youtu.be/sUctgSnSARM?feature=shared">talk</a>
              /
              <a href="https://github.com/ind1010/SfM_for_BusEdge">code</a>
              <p>Developed a data-efficient computer vision method to detect hazardous, snow-covered sidewalks in images from bus routes by combining Structure from Motion with a segmentation model.</p>
            </td>
          </tr> 

          <tr onmouseout="mip360_stop()" onmouseover="mip360_start()"  bgcolor="#ffffff">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <!-- <div class="one">
                <div class="two" id='mip360_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/segmented_flipbook.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div> -->
                <img src='images/agu_image.jpg' width="160">
              <!-- </div> -->
              <!-- <script type="text/javascript">
                function mip360_start() {
                  document.getElementById('mip360_image').style.opacity = "1";
                }

                function mip360_stop() {
                  document.getElementById('mip360_image').style.opacity = "0";
                }
                mip360_stop()
              </script> -->
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <!-- <a href="http://jonbarron.info/mipnerf360"> -->
                <papertitle><a href="https://ui.adsabs.harvard.edu/abs/2022AGUFMPP15A..03M/abstract" style="font-size:18px">Multispectral Petrography Image Analysis as a Method for Paleoenvironmental and Paleoecological Reconstruction; Applications to Earth's First Reefs</a></papertitle>
              <!-- </a> -->
              <br>
              Ryan Manzuk, Bolton Howes, Emily Geyman, <strong>Indu Panigrahi</strong>, Devdigvijay Singh, Adam Maloof
              <br>
              <em>AGU Fall Meeting</em>, 2022
              <br>
              <a href="https://ui.adsabs.harvard.edu/abs/2022AGUFMPP15A..03M/abstract">abstract</a>
              <p>This presentation covered work in the Maloof Research Group on using petrographic imaging and computer vision to bring high-throughput, fine-scale, geophysical data to the study of carbonate outcrops and Earth history.</p>
              <!-- @inproceedings{manzuk2022multispectral,
                address = {Chicago, Illinois},
                author = {\textbf{Manzuk, Ryan A.} and Howes, Bolton J and  Geyman, Emily C and Panigrahi, Indu and Singh, Devdigvijay and Maloof, Adam C},
                booktitle = {AGU Fall Meeting 2022},
                date-added = {2022-10-07 10:13:55 -0500},
                date-modified = {2022-10-07 10:23:28 -0500},
                number = {PP15A-03},
                title = {Multispectral Petrography Image Analysis as a Method for Paleoenvironmental and Paleoecological Reconstruction; Applications to Earth's First Reefs},
                year = {2022}} -->
            </td>
          </tr> 
        </tbody></table>


<!-- MORE RESEARCH EXPERIENCES -->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:bottom" id="resexp">
              <heading><i class="fa fa-flask" aria-hidden="true" style="color:#005CE6"></i> More Research Experiences</heading>
              <p>
                In addition to the experiences that led to the publications/preprints above, I've had the opportunity for other (related) research experiences!
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr bgcolor="#ffffff">
            <td style="padding:20px;width:25%;vertical-align:middle">
                <img src='images/thesis.jpeg' width="160">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <!-- <a href="http://jonbarron.info/mipnerf360"> -->
                <papertitle><a href="https://drive.google.com/file/d/1s7sbPHTLP3JDx3BZNwMoMW62fRVd6vHz/view?usp=sharing" style="font-size:18px">Is it Cake? A Recipe for Data-Efficient Fossil Identification</a></papertitle>
              <!-- </a> -->
              <br>
              <strong>Indu Panigrahi</strong> (Advised by Dr. Ruth Fong & Prof. Adam Maloof)
              <br>
              <em>Senior Thesis</em>, 2022-2023
              <br>
              <b style="color:#FF9300"><i class="fa fa-trophy" aria-hidden="true" style="color:#FF9300"></i>
Outstanding Computer Science Senior Thesis Prize</b>
              <br>
              <a href="https://drive.google.com/file/d/1s7sbPHTLP3JDx3BZNwMoMW62fRVd6vHz/view?usp=sharing">thesis</a>
              /
              <a href="https://youtu.be/4NCs-_wH-Ic?feature=shared">talk</a>
              <p>Created a data-efficient and generalizable computer vision model that leverages self-supervised learning and curriculum learning to improve the segmentation of fossils from an impactful rock sample dataset.</p>
            </td>
          </tr> 

          <tr onmouseout="mip360_stop()" onmouseover="mip360_start()"  bgcolor="#ffffff">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='mip360_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/segmented_flipbook.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/stack.jpg' width="160">
              </div>
              <script type="text/javascript">
                function mip360_start() {
                  document.getElementById('mip360_image').style.opacity = "1";
                }

                function mip360_stop() {
                  document.getElementById('mip360_image').style.opacity = "0";
                }
                mip360_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <!-- <a href="http://jonbarron.info/mipnerf360"> -->
                <papertitle><a href="https://drive.google.com/file/d/1DP7fokAe1Hxi6mFi4lzlZdJGzGxubo34/view?usp=sharing" style="font-size:18px">Incorporating Inter-Image Communication to Improve Serial Image Segmentation</a></papertitle>
              <!-- </a> -->
              <br>
              <strong>Indu Panigrahi</strong> (Advisor: Prof. Adam Maloof, Secondary Advisor: Prof. Jia Deng)
              <br>
              <em>Junior Independent Work</em>, Fall 2021
              <br>
              <a href="https://drive.google.com/file/d/1DP7fokAe1Hxi6mFi4lzlZdJGzGxubo34/view?usp=sharing">report</a>
              /
              <a href="https://www.youtube.com/watch?v=tYY-NcinOmM">talk</a>
              /
              <a href="https://github.com/ind1010/detectron2">code</a>
              <p>Designed and implemented an inter-image communication mechanism that manipulates the Region Proposal Network of a Mask R-CNN to improve the segmentation consistency of a serial image dataset.</p>
              <!-- <p>We find that communicating the coordinates of identified archaeocyathids from one layer to the next during inference and influencing the regions that the model prioritizes in the image improves the consistency of the segmentation of the layers.</p> -->
            </td>
          </tr> 

          <tr onmouseout="refnerf_stop()" onmouseover="refnerf_start()">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <div class="two" id='refnerf_image'><video  width=100% height=100% muted autoplay loop>
          <source src="images/3dmodel.mp4" type="video/mp4">
          Your browser does not support the video tag.
          </video></div>
          <img src='images/labrador.jpg' width="160">
        </div>
        <script type="text/javascript">
          function refnerf_start() {
            document.getElementById('refnerf_image').style.opacity = "1";
          }

          function refnerf_stop() {
            document.getElementById('refnerf_image').style.opacity = "0";
          }
          refnerf_stop()
        </script>
      </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
            <papertitle><a href="https://mediacentral.princeton.edu/media/ReMatch%2B++Intern+-+Indu+Panigrahi/1_dvazfben/218262183" style="font-size:18px">Automating Three-dimensional Modeling of an Archaeocyathid reef using a Mask R-CNN</a></papertitle>
          <br>
          <strong>Indu Panigrahi</strong> (Advised by Dr. Ryan Manzuk & Prof. Adam Maloof)
          <br>
            <em><a href="https://undergraduateresearch.princeton.edu/programs/summer-programs/rematchplus">ReMatch+ Summer Program</a></em>, Summer 2021
          <br>
          <a href="https://mediacentral.princeton.edu/media/ReMatch%2B++Intern+-+Indu+Panigrahi/1_dvazfben/218262183">talk</a>
          <p>Using a Mask R-CNN, we segmented an image stack of cross sections of a rock sample encasing extinct reef-building organisms and stacked the segmented images to form a three-dimensional model of the embedded specimens.</p>
        </td>
      </tr>

        </tbody></table>


<!-- PROJECTS -->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:bottom" id="projects">
              <heading><i class="fa fa-folder-open" aria-hidden="true" style="color:#005CE6"></i> Course Projects</heading>
              <!-- <p> -->
                <!-- Through my coursework, I've had the opportunity to work across several topics in addition to AI/ML. -->
                <!-- Within computer vision, I am interested in network architecture (i.e., the structure of computer vision models) and interpretability (i.e., how computer vision models learn and recognize). These aspects complement each other because understanding the latter involves examining the former, and both seek to comprehend how computer vision models work and whether or not they truly accomplish the task at hand. I find these areas worthwhile and engaging because working at the intersection of computer and geophysical sciences has shown me the importance of the transparency of models. Transparency helps increase the trust of users, and for fields in which computer vision is extraordinarily useful, such as geosciences, domain experts may find a description of a computer vision model that seems to apply to their own research but need a simple way to convince themselves of the reliability of the model for their particular application. -->
               <!--  I'm interested in computer vision, machine learning, optimization, and image processing. Much of my research is about inferring the physical world (shape, motion, color, light, etc) from images. Representative papers are <span class="highlight">highlighted</span>. -->
              <!-- </p> -->
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
                <img src='images/embunkbed.jpeg' width="160">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle;">
                <papertitle><a href="https://github.com/brooksca3/EmBunkBed/blob/main/Brooks_Panigrahi_COS_557_Paper.pdf" style="font-size:18px">Exploring Tokenization Techniques for Protein Language Models</a></papertitle>
              <br>
              Creston Brooks* and <strong>Indu Panigrahi*</strong>
              <br>
              <em>AI for Precision Health (COS 557)</em>, Spring 2024
              <br>
              <a href="https://github.com/brooksca3/EmBunkBed/blob/main/Brooks_Panigrahi_COS_557_Paper.pdf">paper</a>
              /
              <a href="https://github.com/brooksca3/EmBunkBed">code</a>
              <p>
              We compared different tokenization techniques for protein sequences to combine amino acid-level information with sequence-level motifs.
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
                <img src='images/rainforest.jpeg' width="160">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle;">
                <papertitle><a href="https://arxiv.org/abs/2402.18742" style="font-size:18px">Comparing Importance Sampling Based Methods for Mitigating the Effect of Class Imbalance</a></papertitle>
              <br>
              <strong>Indu Panigrahi*</strong> and Richard Zhu*
              <br>
              <em>Fundamentals of Deep Learning (COS 514)</em>, Fall 2023
              <br>
              <a href="https://arxiv.org/abs/2402.18742">arXiv</a>
              /
              <a href="https://github.com/RichardZhu123/514-class-imbalance">code</a>
              <p>
              Using Planet's Amazon Rainforest dataset, we investigate and compare the effectiveness of three techniques for mitigating data imbalance that derive from importance sampling: loss reweighting, undersampling, and oversampling.
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
                <img src='images/defi.jpeg' width="160">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle;">
                <papertitle><a href="https://drive.google.com/file/d/15noaDv0u6M5Zx3ohYEkw6vwQ2jNvPxUq/view?usp=sharing" style="font-size:18px">Smibbit: The Worldâ€™s First Public Wash Trading Detector</a></papertitle>
              <br>
              <strong>Indu Panigrahi*</strong> and Alexis Sursock*
              <br>
              <em>Elements of Decentralized Finance (ECE 473)</em>, Spring 2023
              <br>
              <a href="https://drive.google.com/file/d/15noaDv0u6M5Zx3ohYEkw6vwQ2jNvPxUq/view?usp=sharing">paper</a>
              /
              <a href="https://drive.google.com/file/d/1gikH9WnQS548HztdQjuPoZ9bBIAZf2ca/view?usp=sharing">poster</a>
              <p>
              We implemented several methods for detecting wash trading and built a user interface that utilized these methods to flag user-specified NFTs. <br>
              <b style="color:#FF9300"><i class="fa fa-trophy" aria-hidden="true" style="color:#FF9300"></i>
DeCenter Spring Conference Outstanding Poster Prize</b>
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
                <img src='images/robotics.jpeg' width="160">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle;">
                <papertitle><a href="images/robotics.mp4" style="font-size:18px">Implementing a vision-controlled quadrotor</a></papertitle>
              <br>
              Albert Lin*, Raymond Liu*, <strong>Indu Panigrahi*</strong>, Nobline Yoo*
              <br>
              <em>Introduction to Robotics (MAE 345)</em>, Fall 2022
              <br>
              <p>
              We worked in a team to implement a vision-based controller on a quadrotor using concepts from motion planning, control, localization, and computer vision.
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
                <img src='images/nlp_proj.jpeg' width="160">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle;">
                <papertitle><a href="https://github.com/ind1010/Region-under-discussion-for-visual-dialog/blob/main/COS484_Report_Panigrahi_Liu.pdf" style="font-size:18px">OSCAR: Occluding Spatials, Category, And Region under discussion</a></papertitle>
              <br>
              Raymond Liu* and <strong>Indu Panigrahi*</strong>
              <br>
              <em>Natural Language Processing Final Project (COS 484)</em>, Spring 2022
              <br>
              <a href="https://github.com/ind1010/Region-under-discussion-for-visual-dialog/blob/main/COS484_Poster.pdf">poster</a>
              /
              <a href="https://github.com/ind1010/Region-under-discussion-for-visual-dialog/blob/main/COS484_Report_Panigrahi_Liu.pdf">paper</a>
              /
              <a href="https://github.com/ind1010/Region-under-discussion-for-visual-dialog">code</a>
              <p>
              Reproduced a Visual Dialog model from an EMNLP 2021 paper and performed novel ablations and experiments to analyze and improve the input embedding.
              </p>
            </td>
          </tr>


<tr onmouseout="ddp_stop()" onmouseover="ddp_start()">
    <td style="padding:20px;width:25%;vertical-align:middle">
      <div class="one">
        <div class="two" id='ddp_image'>
          <img src='images/ped_masked.jpg' width="160"></div>
        <img src='images/ped.jpg' width="160">
      </div>
      <script type="text/javascript">
        function ddp_start() {
          document.getElementById('ddp_image').style.opacity = "1";
        }

        function ddp_stop() {
          document.getElementById('ddp_image').style.opacity = "0";
        }
        ddp_stop()
      </script>
    </td>
    <td style="padding:20px;width:75%;vertical-align:middle;">
        <papertitle><a href="data/COS429_Report.pdf" style="font-size:18px">Pedestrian Detection and Interpretability</a></papertitle>
      <br>
      Raymond Liu* and <strong>Indu Panigrahi*</strong>
      <br>
      <em>Computer Vision Final Project (COS 429)</em>, Fall 2021
      <br>
      <a href="images/COS429Poster.jpeg">poster</a>
      /
      <a href="data/COS429_Report.pdf">paper</a>
      /
      <a href="https://github.com/ind1010/pedestrian_detection_interpretability">code</a>
      <p></p>
      <p>
      We enhanced pedestrian detection with Faster R-CNN by modifying the loss function to upweight images that lack visual cues, such as crosswalks.
      </p>
    </td>
  </tr>


  <tr onmouseout="tigertools_stop()" onmouseover="tigertools_start()">
    <td style="padding:20px;width:25%;vertical-align:middle">
      <div class="one">
        <div class="two" id='tigertools_im'>
          <img src='images/tigertools_after.jpg' width="160"></div>
        <img src='images/tigertools_before.jpg' width="160">
      </div>
      <script type="text/javascript">
        function tigertools_start() {
          document.getElementById('tigertools_im').style.opacity = "1";
        }

        function tigertools_stop() {
          document.getElementById('tigertools_im').style.opacity = "0";
        }
        tigertools_stop()
      </script>
    </td>
    <td style="padding:20px;width:75%;vertical-align:middle;">
      <a href="https://tools.tigerapps.org/">
        <papertitle>TigerTools</papertitle>
      </a>
      <br>
      <strong>Indu Panigrahi (lead)*</strong>, Raymond Liu*, and Adam Rebei* 
      <!-- (Advised by Willie Chang & Prof. Robert Dondero Jr.) -->
      <br>
      <em>COS 333 Term Project</em>, Spring 2021
      <br>
      <a href="https://drive.google.com/drive/folders/1WBKpX8FVK3kdYBmQhhzP9xS8S4ZGU471?usp=sharing">documentation</a>
      /
      <a href="https://github.com/PrincetonUSG/TigerTools">code</a>
      <p></p>
      <p>
      This application allows Princeton University users to find amenities using a map of campus and provide feedback on those amenities. By Indu Panigrahi '23, Raymond Liu '23, and Adam Rebei '23.<br>
      Now hosted by <a href="https://www.tigerapps.org/#campus">TigerApps</a>.
      </p>
    </td>
  </tr>
</tbody></table>
     

<!-- TEACHING AND OUTREACH -->
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
                <tr>
                  <td id="teaching">
                    <heading><i class="fa fa-lightbulb-o" aria-hidden="true" style="color:#005CE6"></i> Teaching & Outreach </heading>
                    <!-- <p>
                      Mentorship is very important to me, having been a mentee when starting research in the first place. In particular, I strive to encourage students, especially early-stage undergrads, to get started in research even if it seems intimidating or if they have no prior research experience.
                    </p> -->
                  </td>
                </tr>
              </tbody></table>
              <table width="100%" align="center" border="0" cellpadding="20"><tbody>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one">
              <div class="two" id='cs_logo'>
                <img src='images/cs_logo.png' width="160"></div>
              <img src='images/cs_logo.png' width="160">
            </div>
          </td>
            <td width="75%" valign="middle">
              Department of Computer Science, Princeton University
              <ul>
                <li><b>Graduate TA:</b> COS 217 Introduction to Programming Systems (Spring 2025, Fall 2024, Spring 2024, Fall 2023) <br></li>
                <li><b>Undergraduate TA:</b> COS 302 Mathematics for Numerical Computing and Machine Learning (Fall 2022, Spring 2022) <br></li>
                <li><b>Undergraduate Grader:</b> COS 217 Introduction to Programming Systems (Spring 2023, Fall 2021, Spring 2021) <br></li>
              </ul>
              <b style="color:#FF9300"><i class="fa fa-trophy" aria-hidden="true" style="color:#FF9300"></i>
Outstanding Student Teaching Award (Undergrad)</b>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one">
              <div class="two" id='our_logo'>
                <img src='images/our_logo.jpeg' width="160"></div>
              <img src='images/our_logo.jpeg' width="160">
            </div>
          </td>
            <td width="75%" valign="middle">
              Office of Undergraduate Research, Princeton University<br>
              <p style="margin-left: 20px;">As a ReMatch+ alumna, I often volunteer for OUR as a
              <ul>
                <li><b>Mentor for the ReMatch+ and OURSIP programs:</b> Hosted weekly support sessions for summer interns at Princeton to discuss directions for progressing their research and ideas for making their concluding presentations accessible to a general audience. (Summer 2023, Summer 2024) <br></li>
                <li><b>Judge for <a href="https://researchday.princeton.edu/" style="color:#000000;">Princeton Research Day</a>:</b> Evaluated video submissions to PRD based on clarity and accessibility to non-expert audiences. (2023, 2024)</li>
                <li><b>Student Outreach Volunteer:</b> Help with ad-hoc information sessions and outreach events.</li><p>
              </ul>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one">
              <div class="two" id='ai4all_logo'>
                <img src='images/ai4all_logo.png' width="160"></div>
              <img src='images/ai4all_logo.png' width="160">
            </div>
          </td>
            <td width="75%" valign="middle">
              <a href="https://ai-4-all.org/" style="color:#000000;">AI4ALL</a> Summer Camp, Princeton University
              <ul>
                <li><b>Volunteer Research Instructor:</b> Taught and helped develop an AI/ML curriculum for high school students underrepresented in AI research. (Summer 2023, Summer 2024) 
                <br><br>
                In 2023, my co-instructors and I designed and mentored a project on exploring the effect of data on ML models by applying computer vision to satellite images to track deforestation (<a href="https://engineering.princeton.edu/news/2023/08/02/ai4all-summer-program-featured-nbc-today-show">Media Coverage</a>). In 2024, I played a supporting instructor role and helped guide students through the results and final presentation portion of a project that tackled data imbalance in medical imaging.  <br></li>
              </ul>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one">
              <div class="two" id='robolaunch_logo'>
                <img src='images/robolaunch_logo.jpeg' width="160"></div>
              <img src='images/robolaunch_logo.jpeg' width="160">
            </div>
          </td>
            <td width="75%" valign="middle">
              RoboLaunch, Carnegie Mellon University
              <ul>
                <li><b>Workshop Co-organizer:</b> Co-organized an introductory workshop on PID control for a robotics outreach initiative while interning at CMU. (Summer 2022, <a href="https://www.youtube.com/watch?v=dR0nTvZqabQ">Recording</a>) <br></li>
              </ul>
            </td>
          </tr>
      </tbody></table>


<!-- COMMITTEE SERVICE -->
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td id="committee">
              <heading><i class="fa fa-users" aria-hidden="true" style="color:#005CE6"></i> Committee Service</heading>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>

          <tr>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <ul>
                <li><b>Workshop Organizer</b>
                  <p style="margin-left: 20px;">
                    CVPR 2026 Explainable AI for Computer Vision (<a href="https://xai4cv.github.io/workshop_cvpr25" style="color:#000000;">XAI4CV</a>) Workshop (if accepted)
                  <br>CVPR 2025 <a href="https://xai4cv.github.io/workshop_cvpr25" style="color:#000000;">XAI4CV</a> Workshop
                  <br>CVPR 2024 <a href="https://xai4cv.github.io/workshop_cvpr24" style="color:#000000;">XAI4CV</a> Workshop (<b>Lead Organizer</b>, <a href="https://www.youtube.com/watch?v=o2YmzPXtAgc&ab_channel=ComputerVisionFoundationVideos">Recording</a>)</p></li>
                
                <li><b>Reviewer</b> <br>
                  <p style="margin-left: 20px;">
                    <a href="https://iui.acm.org/2026/" style="color:#000000;">IUI 2026</a>
                  <br>CVPR 2025 Workshops (<a href="https://sites.google.com/view/pixfoundation" style="color:#000000;">PixFoundation</a>, <a href="https://xai4cv.github.io/workshop_cvpr25" style="color:#000000;">XAI4CV</a>, <a href="https://sites.google.com/view/wicv-cvpr-2025/" style="color:#000000;">WiCV</a>)
                  <br><a href="https://scslworkshop.github.io/" style="color:#000000;">ICLR 2025 SCSL Workshop</a>
                  <br><a href="https://iui.acm.org/2025/" style="color:#000000;">IUI 2025</a>
                  <br>CVPR 2024 Workshops (<a href="https://sites.google.com/view/l3divu2024/overview" style="color:#000000;">L3D-IVU</a>, <a href="https://xai4cv.github.io/workshop_cvpr24" style="color:#000000;">XAI4CV</a>, <a href="https://sites.google.com/view/wicv-cvpr-2024/" style="color:#000000;">WiCV</a>)
                  <br> ECCV 2024 Workshops (<a href="https://sites.google.com/view/ai4vaeccv2024" style="color:#000000;">AI4VA</a>, <a href="https://www.ood-cv.org/" style="color:#000000;">OOD-CV</a>)
                  <br> CVPR 2023 <a href="https://xai4cv.github.io/workshop_cvpr23" style="color:#000000;">XAI4CV</a> Workshop</p></li>
                <!-- <li><b>Judge</b><br>
                  <p style="margin-left: 20px;">Princeton Research Day (2023, 2024)</p></li> -->
                
                <li><b>Princeton University Graduate COS Council</b><br>
                  <p style="margin-left: 20px;">Communications Co-chair (2024-2025)</p></li>
              </ul>
          </td>
            <!-- <td width="75%" valign="center">
              Princeton University <br>
              M.S.E. in Computer Science <br><br>
              <strong>Coursework:</strong> Probabilistic Topics in Reinforcement Learning (COS 597R), Spatial Computing (COS 597U), AI for Precision Health (COS 557), Fundamentals of Deep Learning (COS 514)
            </td> -->
          </tr>
          
        </tbody></table>


<!-- EDUCATION -->
   <!--    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td id="education">
              <heading><i class="fa fa-graduation-cap" aria-hidden="true" style="color:#005CE6"></i> Education</heading>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one">
              <div class="two" id='princeton_logo'>
                <img src='images/princeton_logo.png' width="160"></div>
              <img src='images/princeton_logo.png' width="160">
            </div>
          </td>
            <td width="75%" valign="center">
              Princeton University <br>
              M.S.E. in Computer Science <br><br>
              <strong>Coursework</strong>: Probabilistic Topics in Reinforcement Learning (COS 597R), Spatial Computing (COS 597U), AI for Precision Health (COS 557), Fundamentals of Deep Learning (COS 514)
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one">
              <div class="two" id='princeton_logo'>
                <img src='images/princeton_logo.png' width="160"></div>
              <img src='images/princeton_logo.png' width="160">
            </div>
          </td>
            <td width="75%" valign="center">
              Princeton University - Class of 2023 <br>
              B.S.E. in Computer Science, Certificate in Statistics & Machine Learning <br>
              <a href="https://dataspace.princeton.edu/handle/88435/dsp010z709073j">Senior Thesis: Is it Cake? A Recipe for Data-Efficient Fossil Identification</a><br><br>
              <b>Graduate Coursework:</b> Information Theory and Applications (COS 585) <br>
              <b>Relevant Undergraduate Coursework:</b> Robotics (MAE 345), Computer Vision (COS 429), Natural Language Processing (COS 484), Statistics & Data Analysis (SML 201), Mathematics for Machine Learning (COS 302), Advanced Programming (COS 333), Algorithms and Data Structures (COS 226), Computational Biology (COS 343), Contemporary Logic Design (ECE 206)
            </td>
          </tr>
					
					
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                This website was adapted from <a href="https://github.com/jonbarron/jonbarron_website">this GitHub repository</a>
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table> -->
</body>

</html>
